import React, { useState, useEffect, useCallback } from 'react';
import Button from '../components/Button.tsx';
import Card from '../components/Card.tsx';
import PageLayout from '../components/PageLayout.tsx';
import PersonaTransitionSlide from '../components/PersonaTransitionSlide.tsx';
import BackButton from '../components/BackButton.tsx';
import ContinueButton from '../components/ContinueButton.tsx';
import { Page, UserData } from '../types.ts';
import { SCRIPTS, DEEPFAKE_PEOPLE_DATA, DEEPFAKE_IDENTIFICATION_VIDEO_URL, NARRATOR_VOICE_ID } from '../constants.tsx';
import * as apiService from '../services/apiService.ts';
import { scheduleNarrationPreload } from '../utils/narrationPreloader.ts';

interface DeepfakeIntroductionPageProps {
  setCurrentPage: (page: Page) => void;
  userData: UserData | null;
  caricatureUrl: string | null;
  voiceId: string | null;
  talkingPhotoUrl: string | null;
  currentStep: number;
  setCurrentStep: (step: number) => void;
  onGoBack: () => void;
  canGoBack: boolean;
}

const DeepfakeIntroductionPage: React.FC<DeepfakeIntroductionPageProps> = ({
  setCurrentPage,
  userData,
  caricatureUrl,
  voiceId,
  talkingPhotoUrl,
  currentStep,
  setCurrentStep,
  onGoBack,
  canGoBack,
}) => {
  const [currentStepIndex, setCurrentStepIndex] = useState(currentStep || 0);
  const [preloadingNext, setPreloadingNext] = useState(false);
  const [videoEnded, setVideoEnded] = useState(false);

  // Sync local step with global step tracking
  useEffect(() => {
    if (currentStepIndex !== currentStep) {
      setCurrentStep(currentStepIndex);
    }
  }, [currentStepIndex, currentStep, setCurrentStep]);

  // Reset video ended state when step changes
  useEffect(() => {
    setVideoEnded(false);
  }, [currentStepIndex]);

  const steps = [
    {
      id: 'video-intro-narration',
      title: 'AI, ì–¼ë§ˆë‚˜ ë˜‘ë˜‘í•´ì¡Œì„ê¹Œìš”?',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeIntroStart,
      requires: ['userCaricature'],
    },
    {
      id: 'deepfake-concept',
      title: 'AIê°€ ì–¼êµ´ì„ ë°”ê¾¸ëŠ” ê¸°ìˆ ',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeConcept,
      requires: ['userCaricature'],
    },
    {
      id: 'deepvoice-concept',
      title: 'AIê°€ ëª©ì†Œë¦¬ë¥¼ í‰ë‚´ë‚´ìš”',
      type: 'narration',
      narrationScript: SCRIPTS.deepvoiceConcept,
      requires: ['userCaricature'],
    },
    {
      id: 'deepfake-transition',
      title: 'ì´ëŸ° ì˜ìƒì€ ì–´ë–»ê²Œ ë§Œë“¤ê¹Œìš”?',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeVideoIntro,
      requires: ['userCaricature'],
    },
    {
      id: 'concept-video',
      type: 'info',
      content: (
        <div className="text-center">
          <h3 className="text-2xl font-bold mb-6 text-orange-600">ë”¥í˜ì´í¬ì™€ ë”¥ë³´ì´ìŠ¤ ê¸°ìˆ ì´ë€?</h3>
          <div className="aspect-video bg-gray-100 rounded-lg mb-6 flex items-center justify-center">
            <video 
              controls 
              autoPlay
              className="w-full h-full rounded-lg"
              src={DEEPFAKE_IDENTIFICATION_VIDEO_URL}
              onEnded={() => setVideoEnded(true)}
            >
              <p>ë¸Œë¼ìš°ì €ê°€ ë™ì˜ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
            </video>
          </div>
          {/* <p className="text-gray-600 text-lg">
            ìœ„ ì˜ìƒì„ í†µí•´ ë”¥í˜ì´í¬ì™€ ë”¥ë³´ì´ìŠ¤ ê¸°ìˆ ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
          </p> */}
        </div>
      ),
    },
    {
      id: 'deepfake-transition',
      title: 'AIê°€ ì‚¬ëŒê¹Œì§€ ë§Œë“¤ì–´ë‚¸ë‹¤ê³ ìš”?',
      type: 'narration',
      narrationScript: SCRIPTS.genAIConcept,
      requires: ['userCaricature'],
    },
    {
      id: 'deepfake-transition',
      title: 'AIê°€ ì‚¬ëŒê¹Œì§€ ë§Œë“¤ì–´ë‚¸ë‹¤ê³ ìš”?',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeWrapup,
      requires: ['userCaricature'],
    },
    {
      id: 'quiz-intro-narration',
      title: 'ì§„ì§œì¸ì§€ ë§í˜€ë³´ì„¸ìš”!',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeQuizIntro,
      requires: ['userCaricature'],
    },
    {
      id: 'deepfake-quiz-1',
      title: 'ì´ ì˜ìƒ, ì§„ì§œì¼ê¹Œìš”?',
      type: 'info',
      content: (
        <div className="text-center">
          <p className="text-gray-600 text-lg mb-6">
            ì´ ì˜ìƒì´ ì§„ì§œì¸ì§€ AIë¡œ ìƒì„±ëœ ê°€ì§œ ì˜ìƒì¸ì§€ íŒë‹¨í•´ë³´ì„¸ìš”.
          </p>
          <div className="aspect-video bg-gray-100 rounded-lg mb-6 flex items-center justify-center">
            <video 
              controls 
              autoPlay
              className="w-full h-full rounded-lg"
              src={DEEPFAKE_PEOPLE_DATA[0].videoUrl}
              onEnded={() => setVideoEnded(true)}
            >
              <p>ë¸Œë¼ìš°ì €ê°€ ë™ì˜ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
            </video>
          </div>
          {/* <p className="text-gray-600 text-lg">
            ëˆˆ, ì…ì˜ ì›€ì§ì„, ëª©ì†Œë¦¬ í†¤ ë“±ì„ ìì„¸íˆ ì‚´í´ë³´ì„¸ìš”.
          </p> */}
        </div>
      ),
    },
    {
      id: 'quiz-feedback-1',
      title: 'AIê°€ ë§Œë“  ë”¥í˜ì´í¬ ì˜ìƒì´ì—ìš”!',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeQuiz1,
      requires: ['userCaricature'],
    },
    {
      id: 'deepfake-quiz-2',
      title: 'ì´ë²ˆ ì˜ìƒì€ ì–´ë–¨ê¹Œìš”?',
      type: 'info',
      content: (
        <div className="text-center">
          <p className="text-gray-600 text-lg mb-6">
          ì²« ë²ˆì§¸ ì˜ìƒê³¼ ë¹„êµí•´ì„œ ì–´ë–¤ ì°¨ì´ì ì´ ìˆëŠ”ì§€ ê´€ì°°í•´ë³´ì„¸ìš”.
          </p>
          <div className="aspect-video bg-gray-100 rounded-lg mb-6 flex items-center justify-center">
            <video 
              controls 
              autoPlay
              className="w-full h-full rounded-lg"
              src={DEEPFAKE_PEOPLE_DATA[1].videoUrl}
              onEnded={() => setVideoEnded(true)}
            >
              <p>ë¸Œë¼ìš°ì €ê°€ ë™ì˜ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
            </video>
          </div>
        </div>
      ),
    },
    {
      id: 'quiz-feedback-2',
      title: 'ì´ê²ƒë„ AIê°€ ë§Œë“  ë”¥í˜ì´í¬ ì˜ìƒì´ì—ìš”!',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeQuiz2,
      requires: ['userCaricature'],
    },
    {
      id: 'quiz-complete-narration',
      title: 'ê°€ì§œ ë‰´ìŠ¤, ì‹ ì› ë„ìš©ì— ì•…ìš© ë¼ìš”!',
      type: 'narration',
      narrationScript: SCRIPTS.deepfakeQuizComplete,
      requires: ['userCaricature'],
    },
  ];

  const handleNext = () => {
    if (currentStepIndex < steps.length - 1) {
      setCurrentStepIndex(currentStepIndex + 1);
    } else {
      // Go to module selection
      setCurrentPage(Page.ModuleSelection);
    }
  };

  const handlePrevious = () => {
    if (currentStepIndex > 0) {
      console.log(`Going back from step ${currentStepIndex} to step ${currentStepIndex - 1}`);
      setCurrentStepIndex(currentStepIndex - 1);
    } else {
      // If at first step, use the global back function to go to previous page
      onGoBack();
    }
  };

  // Start scenario generation when reaching the first step
  const startScenarioGeneration = useCallback(async () => {
    if (!voiceId) {
      console.log('âš ï¸ No voiceId available for scenario generation');
      return;
    }
    
    try {
      console.log('ğŸš€ Starting scenario generation during deepfake introduction...');
      console.log(`   - Voice ID: ${voiceId}`);
      console.log(`   - Step: AI, ì–¼ë§ˆë‚˜ ë˜‘ë˜‘í•´ì¡Œì„ê¹Œìš”?`);
      
      const result = await apiService.startScenarioGeneration(voiceId);
      console.log('âœ… Scenario generation started successfully:', result);
    } catch (error) {
      console.error('âŒ Failed to start scenario generation:', error);
      // Non-critical error, continue with the flow
    }
  }, [voiceId]);

  // Preload next step's narration using the new utility
  const preloadNextNarration = useCallback((currentStepIndex: number) => {
    const nextStepIndex = currentStepIndex + 1;
    if (nextStepIndex >= steps.length) return; // No next step
    
    const nextStep = steps[nextStepIndex];
    if (nextStep.type !== 'narration' || !nextStep.narrationScript) return;
    
    if (!userData?.userId || !voiceId) return;
    
    console.log(`ğŸµ Scheduling preload for step ${nextStep.id}`);
    return scheduleNarrationPreload(nextStep.narrationScript, voiceId, 2000);
  }, [steps, userData?.userId, voiceId]);

  const currentStepData = steps[currentStepIndex];

  // Trigger scenario generation on first step and preload narrations
  useEffect(() => {
    if (userData?.userId && voiceId) {
      // Trigger scenario generation on the first step
      if (currentStepIndex === 0 && currentStepData?.id === 'video-intro-narration') {
        console.log('ğŸ¯ Reached first step - triggering scenario generation');
        startScenarioGeneration();
      }
      // Preload for narration steps
      if (currentStepData?.type === 'narration' && currentStepData?.narrationScript) {
        console.log(`ğŸµ Scheduling voice preload from narration: ${currentStepData.id}`);
        const preloadTimer = preloadNextNarration(currentStepIndex);
        return () => {
          if (preloadTimer) clearTimeout(preloadTimer);
        };
      }
      
      // Preload for info steps with video content (concept video, quiz videos)
      if (currentStepData?.type === 'info' && currentStepData?.content) {
        console.log(`ğŸµ Scheduling voice preload from info/video step: ${currentStepData.id}`);
        const preloadTimer = preloadNextNarration(currentStepIndex);
        return () => {
          if (preloadTimer) clearTimeout(preloadTimer);
        };
      }

      // Pre-generate module selection narration on the final step
      if (currentStepData?.id === 'quiz-complete-narration' && currentStepData?.type === 'narration') {
        console.log('ğŸµ Pre-generating module selection narration for final step');
        const preloadTimer = setTimeout(async () => {
          try {
            console.log('ğŸµ Generating module selection narration one step ahead with user voice');
            const result = await apiService.generateNarration(SCRIPTS.moduleSelection, voiceId);
            
            // Create audio blob and cache it
            const audioBlob = new Blob([Uint8Array.from(atob(result.audioData), c => c.charCodeAt(0))], { type: result.audioType });
            const audioUrl = URL.createObjectURL(audioBlob);
            
            // Cache the audio for ModuleSelectionPage
            if (!(window as any).narrationCache) {
              (window as any).narrationCache = new Map();
            }
            const scriptKey = `${SCRIPTS.moduleSelection}-${voiceId}`;
            (window as any).narrationCache.set(scriptKey, audioUrl);
            
            console.log('âœ… Module selection narration pre-generated and cached');
          } catch (error) {
            console.error('âš ï¸ Failed to pre-generate module selection narration:', error);
          }
        }, 3000); // Start pre-generation after 3 seconds
        
        return () => clearTimeout(preloadTimer);
      }
    }
  }, [currentStepIndex, preloadNextNarration, startScenarioGeneration, userData?.userId, voiceId, currentStepData]); // Updated dependencies

  const renderStepContent = () => {
    switch (currentStepData.type) {
      case 'narration':
        return (
          <Card>
            <div className="text-center">
              <h3 className="text-2xl font-bold mb-6 text-orange-600">{currentStepData.title}</h3>
              <PersonaTransitionSlide
                onNext={handleNext}
                onPrevious={currentStepIndex > 0 ? handlePrevious : undefined}
                userData={userData}
                caricatureUrl={caricatureUrl}
                voiceId={voiceId}
                talkingPhotoUrl={talkingPhotoUrl}
                script={currentStepData.narrationScript || ''}
                chunkedDisplay={true}
                showScript={false} // Set to false to hide script and show only talking photo
              />
            </div>
          </Card>
        );

      case 'info':
        return (
          <Card>
            <div className="text-center">
              <h3 className="text-2xl font-bold mb-6 text-orange-600">{currentStepData.title}</h3>
              {currentStepData.content}
              <div className="mt-8 flex justify-center items-center space-x-4">
                {/* {currentStepIndex > 0 && (
                  <BackButton onClick={handlePrevious} size="lg" variant="primary" />
                )} */}
                <ContinueButton onClick={handleNext} showAnimation={videoEnded} />
              </div>
            </div>
          </Card>
        );

      case 'quiz':
        return (
          <Card>
            <div className="text-center">
              <h3 className="text-2xl font-bold mb-6 text-orange-600">{currentStepData.title}</h3>
              {currentStepData.content}
              <div className="mt-8 flex justify-center items-center space-x-4">
                {/* {currentStepIndex > 0 && (
                  <BackButton onClick={handlePrevious} size="lg" variant="primary" />
                )} */}
                <ContinueButton onClick={handleNext} text="ë‹¤ìŒ" showAnimation={true} />
              </div>
            </div>
          </Card>
        );

      default:
        return (
          <Card>
            <div className="text-center">
              <h3 className="text-2xl font-bold mb-4 text-orange-600">{currentStepData.title}</h3>
              <p className="text-gray-600 mb-6">ë‹¨ê³„ ë‚´ìš©ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</p>
              <ContinueButton onClick={handleNext} text="ë‹¤ìŒ" showAnimation={true} />
            </div>
          </Card>
        );
    }
  };

  return (
    <PageLayout >
      {/* Back Button */}
      {/* {(canGoBack || currentStepIndex > 0) && currentStepData.type !== 'narration' && (
        <div className="mb-6">
          <BackButton onClick={handlePrevious} />
        </div>
      )} */}

      

      {renderStepContent()}
    </PageLayout>
  );
};

export default DeepfakeIntroductionPage;