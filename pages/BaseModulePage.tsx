import React, { useState, useEffect, useCallback, useRef } from 'react';
import Button from '../components/Button.tsx';
import Card from '../components/Card.tsx';
import NarrationPlayer from '../components/NarrationPlayer.tsx';
import QuizComponent from '../components/QuizComponent.tsx';
import PageLayout from '../components/PageLayout.tsx';
import LoadingSpinner from '../components/LoadingSpinner.tsx';
import PersonaTransitionSlide from '../components/PersonaTransitionSlide.tsx';
import BackButton from '../components/BackButton.tsx';
import ContinueButton from '../components/ContinueButton.tsx';
import ModuleProgressBar from '../components/ModuleProgressBar.tsx';
import { Page, ModuleStep, QuizQuestion, UserData } from '../types.ts';
import { QUIZZES, SCRIPTS, PLACEHOLDER_USER_IMAGE } from '../constants.tsx';
import * as apiService from '../services/apiService.ts';

interface BaseModulePageProps {
  moduleTitle: string;
  steps: ModuleStep[];
  setCurrentPage: (page: Page) => void;
  onModuleComplete: () => void;
  userData: UserData | null;
  userImageUrl: string | null;
  caricatureUrl: string | null;
  talkingPhotoUrl: string | null;
  voiceId: string | null;
  moduleCompletionMessage: string;
  currentStep: number;
  setCurrentStep: (step: number) => void;
  onGoBack: () => void;
  canGoBack: boolean;
}

const BaseModulePage: React.FC<BaseModulePageProps> = ({
  moduleTitle,
  steps,
  setCurrentPage,
  onModuleComplete,
  userData,
  userImageUrl,
  caricatureUrl,
  talkingPhotoUrl,
  voiceId,
  moduleCompletionMessage,
  currentStep: globalCurrentStep,
  setCurrentStep: setGlobalCurrentStep,
  onGoBack,
  canGoBack,
}) => {
  const [currentStepIndex, setCurrentStepIndex] = useState(globalCurrentStep || 0);
  const [isLoadingStep, setIsLoadingStep] = useState(false);
  const [stepError, setStepError] = useState<string | null>(null);
  const [interactiveContent, setInteractiveContent] = useState<React.ReactNode | null>(null);
  const [currentView, setCurrentView] = useState<'personaTransition' | 'content'>('personaTransition');
  const [scriptForPersona, setScriptForPersona] = useState<string>("");
  const [isChangingStep, setIsChangingStep] = useState(false);
  const [preloadingNext, setPreloadingNext] = useState(false);
  const [videoEnded, setVideoEnded] = useState(false);
  const personaTransitionRef = useRef<any>(null);

  const currentStep = steps[currentStepIndex];

  // Preload next step's narration for instant experience
  const preloadNextNarration = useCallback(async (currentStepIndex: number) => {
    const nextStepIndex = currentStepIndex + 1;
    if (nextStepIndex >= steps.length) return; // No next step
    
    const nextStep = steps[nextStepIndex];
    if (nextStep.type !== 'narration' || !nextStep.narrationScript) return;
    
    if (!userData?.userId || !voiceId) return;
    
    try {
      setPreloadingNext(true);
      console.log(`ğŸš€ Pre-loading narration for step ${nextStep.id}`);
      console.log(`  - User ID: ${userData.userId}`);
      console.log(`  - Step ID: ${nextStep.id}`);
      console.log(`  - Script: "${nextStep.narrationScript?.substring(0, 50)}..."`);
      console.log(`  - Voice ID: ${voiceId}`);
      
      // Call original narration API to cache the next step
      const result = await apiService.generateNarration(nextStep.narrationScript, voiceId);
      
      // Store in the same cache format as NarrationPlayer
      const scriptKey = `${nextStep.narrationScript}-${voiceId}`;
      const audioBlob = new Blob([Uint8Array.from(atob(result.audioData), c => c.charCodeAt(0))], { type: result.audioType });
      const audioUrl = URL.createObjectURL(audioBlob);
      
      // Access the global cache from NarrationPlayer
      (window as any).narrationCache = (window as any).narrationCache || new Map();
      (window as any).narrationCache.set(scriptKey, audioUrl);
      
      console.log(`âœ… Pre-loaded narration for step ${nextStep.id}`);
      console.log(`  - Audio blob created and cached`);
      console.log(`  - Cache key: ${scriptKey.substring(0, 50)}...`);
    } catch (error) {
      console.error(`âš ï¸ Pre-load failed for step ${nextStep.id}:`, error);
      // Pre-load failure is non-critical, continue normally
    } finally {
      setPreloadingNext(false);
    }
  }, [steps, userData?.userId, voiceId]);

  // Sync local step with global step tracking (one-way sync to prevent loops)
  useEffect(() => {
    if (currentStepIndex !== globalCurrentStep) {
      console.log(`ğŸ”„ Syncing step: local ${currentStepIndex} â†’ global ${globalCurrentStep}`);
      setGlobalCurrentStep(currentStepIndex);
    }
  }, [currentStepIndex, globalCurrentStep, setGlobalCurrentStep]);

  // Initialize local step from global step only once
  useEffect(() => {
    if (globalCurrentStep !== currentStepIndex && globalCurrentStep < steps.length && currentStepIndex === 0) {
      console.log(`ğŸ”„ Initializing local step from global: ${globalCurrentStep}`);
      setCurrentStepIndex(globalCurrentStep);
    }
  }, [globalCurrentStep, steps.length]); // Removed currentStepIndex to prevent loop

  useEffect(() => {
    console.log(`ğŸ”„ Step changed to index ${currentStepIndex}: ${currentStep?.title || 'No step'}`);
    setInteractiveContent(null); 
    setStepError(null);

    if (!currentStep) {
      console.log('âš ï¸ No current step found');
      return;
    }
    
    console.log(`ğŸ¨ Setting up step: ${currentStep.title} (type: ${currentStep.type})`);
    setIsLoadingStep(true);
    
    // Video case studies and some other types should skip persona transition
    // But info steps with narrationScript (like detection tips) should have persona transition
    if (currentStep.type === 'video_case_study' || 
        currentStep.type === 'faceswap_scenario' || 
        currentStep.type === 'voice_call_scenario' || 
        currentStep.type === 'video_call_scenario' ||
        currentStep.type === 'quiz') {
      console.log(`ğŸ”„ Skipping persona transition for ${currentStep.type} step`);
      setCurrentView('content');
    } else if (currentStep.type === 'info' && currentStep.narrationScript) {
      // Info steps with narrationScript (like detection tips) should have persona transition
      console.log(`ğŸ”„ Using persona transition for info step with script:`, currentStep.narrationScript?.substring(0, 50) + '...');
      setCurrentView('personaTransition');
      setScriptForPersona(currentStep.narrationScript || '');
    } else {
      console.log(`ğŸ”„ Using persona transition for ${currentStep.type} step with script:`, currentStep.narrationScript?.substring(0, 50) + '...');
      setCurrentView('personaTransition');
      // Use the narrationScript directly from the step
      setScriptForPersona(currentStep.narrationScript || '');
    }
    
    setIsLoadingStep(false); 

  }, [currentStepIndex, steps]); // Removed currentStep to prevent duplicate dependency

  // Reset video ended state when step changes
  useEffect(() => {
    setVideoEnded(false);
  }, [currentStepIndex]);

  // Preload next narration after current step content is ready
  useEffect(() => {
    if (!isLoadingStep && userData?.userId && voiceId) {
      // Preload for persona transition steps (existing functionality)
      if (currentView === 'personaTransition' && currentStep?.narrationScript) {
        console.log(`ğŸµ Scheduling voice preload from persona transition: ${currentStep.id}`);
        const preloadTimer = setTimeout(() => {
          preloadNextNarration(currentStepIndex);
        }, 3000); // Preload after 3 seconds
        
        return () => clearTimeout(preloadTimer);
      }
      
      // NEW: Preload for video case study steps
      if (currentView === 'content' && currentStep?.type === 'video_case_study') {
        console.log(`ğŸµ Scheduling voice preload from video case study: ${currentStep.id}`);
        const preloadTimer = setTimeout(() => {
          preloadNextNarration(currentStepIndex);
        }, 5000); // Preload after 5 seconds to allow video to start
        
        return () => clearTimeout(preloadTimer);
      }
      
      // NEW: Preload for scenario steps (faceswap, voice call, video call)
      if (currentView === 'content' && (
        currentStep?.type === 'faceswap_scenario' || 
        currentStep?.type === 'voice_call_scenario' || 
        currentStep?.type === 'video_call_scenario'
      )) {
        console.log(`ğŸµ Scheduling voice preload from ${currentStep.type}: ${currentStep.id}`);
        const preloadTimer = setTimeout(() => {
          preloadNextNarration(currentStepIndex);
        }, 7000); // Preload after 7 seconds to allow scenario content to load/generate
        
        return () => clearTimeout(preloadTimer);
      }
    }
  }, [currentStepIndex, currentView]); // Added currentView to dependencies

  // Scenario processing functions
  const processFaceswapScenario = async (step: ModuleStep) => {
    try {
      console.log('ğŸ” Debugging faceswap scenario:', {
        userImageUrl,
        userData,
        voiceId,
        step: {
          scenarioType: step.scenarioType,
          baseImageMale: step.baseImageMale,
          baseImageFemale: step.baseImageFemale,
          audioScript: step.audioScript
        }
      });

      if (!userImageUrl || !userData || !voiceId) {
        console.error('âŒ Missing user data:', { userImageUrl: !!userImageUrl, userData: !!userData, voiceId: !!voiceId });
        return <div className="text-red-500">ì‚¬ìš©ì ë°ì´í„°ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.</div>;
      }

      // Check if pre-generated content exists
      let talkingPhotoUrl = null;
      let isSample = false;
      let message = null;

      if (step.scenarioType === 'lottery' && userData.lottery_video_url) {
        console.log('âœ… Using pre-generated lottery video:', userData.lottery_video_url);
        talkingPhotoUrl = userData.lottery_video_url;
      } else if (step.scenarioType === 'crime' && userData.crime_video_url) {
        console.log('âœ… Using pre-generated crime video:', userData.crime_video_url);
        talkingPhotoUrl = userData.crime_video_url;
      } else {
        // Fallback to real-time generation if pre-generated content not available
        console.log(`âš ï¸ Pre-generated content not found for ${step.scenarioType} scenario, generating in real-time`);
        
        // Select base image based on user gender
        const baseImage = userData.gender === 'male' ? step.baseImageMale : step.baseImageFemale;
        console.log('ğŸ­ Selected base image:', { gender: userData.gender, baseImage });
        
        if (!baseImage) {
          console.error('âŒ No base image found for gender:', userData.gender);
          return <div className="text-red-500">ì‹œë‚˜ë¦¬ì˜¤ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</div>;
        }

        // Generate faceswap image
        console.log(`ğŸ”„ Generating faceswap for ${step.scenarioType} scenario`);
        const faceswapResult = await apiService.generateFaceswapImage(baseImage, userImageUrl);
        console.log('âœ… Faceswap result:', faceswapResult);
        
        // Generate talking photo with scenario-specific audio script
        console.log(`ğŸ”„ Generating talking photo with script: "${step.audioScript}"`);
        const talkingPhotoResult = await apiService.generateTalkingPhoto(faceswapResult.resultUrl, userData.name, voiceId, step.audioScript, step.scenarioType);
        console.log('âœ… Talking photo result:', talkingPhotoResult);
        
        talkingPhotoUrl = talkingPhotoResult.videoUrl;
        isSample = talkingPhotoResult.isSample || false;
        message = talkingPhotoResult.message || null;
      }

      // Download function
      const handleDownload = async () => {
        try {
          const response = await fetch(talkingPhotoUrl);
          const blob = await response.blob();
          const url = window.URL.createObjectURL(blob);
          const link = document.createElement('a');
          link.href = url;
          link.download = `${step.scenarioType === 'lottery' ? 'ë³µê¶Œë‹¹ì²¨' : 'ë²”ì£„ìš©ì˜ì'}_ì‹œë‚˜ë¦¬ì˜¤_${userData.name}.mp4`;
          link.target = '_blank'; // Prevent navigation
          link.rel = 'noopener noreferrer'; // Security
          link.style.display = 'none'; // Hide the link
          document.body.appendChild(link);
          link.click();
          document.body.removeChild(link);
          window.URL.revokeObjectURL(url);
        } catch (error) {
          console.error('Download failed:', error);
          alert('ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        }
      };

      return (
        <div className="text-center">
          <div className="space-y-4">
            <h4 className="text-lg font-semibold text-orange-600">
              {step.scenarioType === 'lottery' ? 'ë³µê¶Œ ë‹¹ì²¨ ì‹œë‚˜ë¦¬ì˜¤' : 'ë²”ì£„ ìš©ì˜ì ì‹œë‚˜ë¦¬ì˜¤'}
            </h4>
            {isSample && message && (
              <div className="mb-4 p-3 bg-orange-100 border border-orange-300 rounded-lg">
                <p className="text-orange-800 font-medium">{message}</p>
              </div>
            )}
            <div className="w-64 h-96 md:w-80 md:h-[30rem] mx-auto bg-gray-100 rounded-lg border-2 border-orange-500 overflow-hidden">
              <video 
                controls 
                autoPlay
                className="w-full h-full object-contain"
                src={talkingPhotoUrl}
                playsInline
                preload="auto"
                disablePictureInPicture
                onEnded={() => setVideoEnded(true)}
              >
                <p>ë¸Œë¼ìš°ì €ê°€ ë™ì˜ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
              </video>
            </div>
            <div className="flex justify-center mt-4">
              <button
                onClick={handleDownload}
                className="px-6 py-3 bg-orange-500 text-white rounded-lg hover:bg-orange-600 transition-colors duration-200 flex items-center space-x-2 shadow-md"
              >
                <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 10v6m0 0l-3-3m3 3l3-3m2 8H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                </svg>
                <span>ì˜ìƒ ë‹¤ìš´ë¡œë“œ</span>
              </button>
            </div>
            <p className="text-sm text-slate-600 italic">
              ì´ëŠ” AI ê¸°ìˆ ì„ ì‚¬ìš©í•´ ìƒì„±ëœ ì˜ìƒì…ë‹ˆë‹¤. 
            </p>
          </div>
        </div>
      );
    } catch (error) {
      console.error('âŒ Error processing faceswap scenario:', error);
      
      // Show more specific error information
      let errorMessage = 'ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      if (error instanceof Error) {
        errorMessage += ` (${error.message})`;
      }
      
      return (
        <div className="text-red-500 p-4 bg-red-50 rounded-lg">
          <div className="font-medium">{errorMessage}</div>
          <div className="text-sm mt-2">ì½˜ì†”ì„ í™•ì¸í•˜ì—¬ ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.</div>
        </div>
      );
    }
  };

  const VoiceVisualization = () => (
    <div className="flex justify-center space-x-1">
      {[...Array(8)].map((_, i) => (
        <div
          key={i}
          className="w-1 bg-green-400 rounded-full animate-pulse"
          style={{
            height: `${Math.random() * 20 + 10}px`,
            animationDelay: `${i * 0.1}s`,
            animationDuration: '0.8s'
          }}
        />
      ))}
    </div>
  );

  const processVoiceCallScenario = async (step: ModuleStep) => {
    try {
      if (!voiceId || !step.audioUrl) {
        return <div className="text-red-500">ìŒì„± ë°ì´í„°ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.</div>;
      }

      // Check if pre-generated audio exists
      let audioData = null;
      let audioType = 'audio/mpeg';

      if (step.scenarioType === 'investment_call' && userData?.investment_call_audio_url) {
        console.log('âœ… Using pre-generated investment call audio:', userData.investment_call_audio_url);
        // Use pre-generated audio URL directly
        audioData = userData.investment_call_audio_url;
      } else if (step.scenarioType === 'accident_call' && userData?.accident_call_audio_url) {
        console.log('âœ… Using pre-generated accident call audio:', userData.accident_call_audio_url);
        // Use pre-generated audio URL directly  
        audioData = userData.accident_call_audio_url;
      } else {
        // Fallback to real-time generation
        console.log(`âš ï¸ Pre-generated audio not found for ${step.scenarioType}, generating in real-time`);
        const narrationResult = await apiService.generateVoiceDub(step.audioUrl, voiceId, step.scenarioType || 'default');
        audioData = `data:${narrationResult.audioType};base64,${narrationResult.audioData}`;
        audioType = narrationResult.audioType;
      }

      return (
        <div className="text-center">
          <div className="bg-gray-900 text-white p-6 rounded-xl max-w-sm mx-auto">
            <div className="text-center space-y-4">
              <div className="w-16 h-16 bg-green-500 rounded-full mx-auto flex items-center justify-center">
                <svg className="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z" />
                </svg>
              </div>
              <p className="text-lg font-semibold">ì¹œêµ¬</p>
              
              {/* Voice visualization during call */}
              <div className="py-4">
                <VoiceVisualization />
                <p className="text-xs text-gray-400 mt-3">í†µí™” ì¤‘...</p>
              </div>
              
              <audio 
                controls 
                autoPlay
                className="w-full mt-4"
                src={audioData}
              />
              <p className="text-xs text-gray-400">ë‹¹ì‹ ì˜ ë³µì œëœ ëª©ì†Œë¦¬ë¡œ ì¬ìƒë©ë‹ˆë‹¤</p>
            </div>
          </div>
        </div>
      );
    } catch (error) {
      console.error('Error processing voice call scenario:', error);
      return <div className="text-red-500">ìŒì„± í†µí™” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</div>;
    }
  };

  const processVideoCallScenario = async (step: ModuleStep) => {
    try {
      if (!voiceId || !step.audioUrl) {
        return <div className="text-red-500">ìŒì„± ë°ì´í„°ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.</div>;
      }

      // Check if pre-generated audio exists
      let audioData = null;
      let audioType = 'audio/mpeg';

      if (step.scenarioType === 'investment_call' && userData?.investment_call_audio_url) {
        console.log('âœ… Using pre-generated investment call audio:', userData.investment_call_audio_url);
        audioData = userData.investment_call_audio_url;
      } else if (step.scenarioType === 'accident_call' && userData?.accident_call_audio_url) {
        console.log('âœ… Using pre-generated accident call audio:', userData.accident_call_audio_url);
        audioData = userData.accident_call_audio_url;
      } else {
        // Fallback to real-time generation
        console.log(`âš ï¸ Pre-generated audio not found for ${step.scenarioType}, generating in real-time`);
        const narrationResult = await apiService.generateVoiceDub(step.audioUrl, voiceId, step.scenarioType || 'default');
        audioData = `data:${narrationResult.audioType};base64,${narrationResult.audioData}`;
        audioType = narrationResult.audioType;
      }

      return (
        <div className="text-center">
          <div className="bg-gray-900 text-white p-6 rounded-xl max-w-sm mx-auto">
            <div className="text-center space-y-4">
              <div className="w-16 h-16 bg-green-500 rounded-full mx-auto flex items-center justify-center">
                <svg className="w-8 h-8" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M2 3a1 1 0 011-1h2.153a1 1 0 01.986.836l.74 4.435a1 1 0 01-.54 1.06l-1.548.773a11.037 11.037 0 006.105 6.105l.774-1.548a1 1 0 011.059-.54l4.435.74a1 1 0 01.836.986V17a1 1 0 01-1 1h-2C7.82 18 2 12.18 2 5V3z" />
                </svg>
              </div>
              <p className="text-lg font-semibold">ê°€ì¡±</p>
              
              {/* Voice visualization during call */}
              <div className="py-4">
                <VoiceVisualization />
                <p className="text-xs text-gray-400 mt-3">í†µí™” ì¤‘...</p>
              </div>
              
              <audio 
                controls 
                autoPlay
                className="w-full mt-4"
                src={audioData}
              />
              <p className="text-xs text-gray-400">ë‹¹ì‹ ì˜ ë³µì œëœ ëª©ì†Œë¦¬ë¡œ ì¬ìƒë©ë‹ˆë‹¤</p>
            </div>
          </div>
        </div>
      );
    } catch (error) {
      console.error('Error processing video call scenario:', error);
      return <div className="text-red-500">ì˜ìƒ í†µí™” ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</div>;
    }
  };

  useEffect(() => {
    if (currentView === 'content' && currentStep) {
        const processContentStep = async () => {
            setIsLoadingStep(true);
            setInteractiveContent(null);
            setStepError(null);

            if (currentStep.type === 'interactive' || (currentStep.type === 'caseStudy' && currentStep.requires && currentStep.requires.length > 0) ) {
                let personalizedContent = currentStep.content || "";
                if (typeof personalizedContent === 'string') {
                   personalizedContent = personalizedContent.replace(/\[Your Name\]/g, userData?.name || "ì‚¬ìš©ì");
                }
                
                await new Promise(resolve => setTimeout(resolve, 300));

                const displayCaricature = caricatureUrl || PLACEHOLDER_USER_IMAGE;

                if (currentStep.requires?.includes('userCaricature') && displayCaricature && currentStep.requires?.includes('userVoice') && voiceId && currentStep.type === 'interactive') {
                     try {
                        const interactiveScript = `ì´ê²ƒì€ ë‹¹ì‹ ì˜ ìºë¦¬ì»¤ì²˜ì™€ ëª©ì†Œë¦¬ë¥¼ ì‚¬ìš©í•œ ê°œì¸í™”ëœ ì‹œë‚˜ë¦¬ì˜¤ ë©”ì‹œì§€ì…ë‹ˆë‹¤: ${personalizedContent}`;
                        await apiService.generateTalkingPhoto(displayCaricature, voiceId, "ëŒ€í™”í˜• ì½˜í…ì¸ ë¥¼ ìœ„í•œ ì§§ì€ ìŒì„±ì…ë‹ˆë‹¤.");
                         setInteractiveContent(
                            <div className="text-center my-4 p-4 bg-slate-50 rounded-lg border border-slate-200">
                                <div className="text-slate-700 text-lg mb-4">{personalizedContent}</div>
                                <img src={displayCaricature} alt="ê°œì¸í™”ëœ ìºë¦¬ì»¤ì²˜" className="rounded-md my-4 w-48 h-48 mx-auto shadow-lg border-2 border-orange-400" />
                                <NarrationPlayer 
                                    script={interactiveScript} 
                                    voiceId={voiceId} 
                                    autoPlay={false} 
                                    showControls={true}
                                    imageUrl={displayCaricature}
                                    talkingImageUrl={talkingPhotoUrl || ""}
                                    chunkedDisplay={true}
                                />
                                <p className="text-sm text-slate-500 italic mt-3">(í˜ë¥´ì†Œë‚˜ê°€ ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì†Œê°œí•œ í›„, ë‹¹ì‹ ì˜ ìºë¦¬ì»¤ì²˜ê°€ ìœ„ ë©”ì‹œì§€ë¥¼ ëª©ì†Œë¦¬ë¡œ ì „ë‹¬í•œë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”.)</p>
                            </div>
                        );
                    } catch (e) { console.error("Error in interactive content talking photo generation", e); setStepError("ëŒ€í™”í˜• ë§í•˜ëŠ” ì½˜í…ì¸  ì˜ˆì œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");}
                } else if (currentStep.type === 'interactive' && !interactiveContent && typeof personalizedContent === 'string') {
                     setInteractiveContent(<p className="text-slate-700 text-lg leading-relaxed">{personalizedContent}</p>);
                }
            }
            
            // Handle new scenario types
            if (currentStep.type === 'faceswap_scenario') {
                console.log('ğŸ”„ Processing faceswap scenario...');
                const processedContent = await processFaceswapScenario(currentStep);
                console.log('âœ… Faceswap scenario processed:', { 
                  hasContent: !!processedContent, 
                  contentType: typeof processedContent 
                });
                setInteractiveContent(processedContent);
                console.log('âœ… InteractiveContent set for faceswap');
            } else if (currentStep.type === 'voice_call_scenario') {
                const processedContent = await processVoiceCallScenario(currentStep);
                setInteractiveContent(processedContent);
            } else if (currentStep.type === 'video_call_scenario') {
                const processedContent = await processVideoCallScenario(currentStep);
                setInteractiveContent(processedContent);
            }
            
            setIsLoadingStep(false);
        };
        processContentStep();
    }
  }, [currentView, currentStep, userData, userImageUrl, caricatureUrl, voiceId]);

  const handleNext = useCallback(() => {
    if (isChangingStep) {
      console.log('âš ï¸ Step change already in progress, ignoring');
      return;
    }
    
    console.log(`ğŸ”„ handleNext called - Current step: ${currentStepIndex}, Total steps: ${steps.length}`);
    setIsChangingStep(true);
    
    // Small delay to prevent rapid step changes
    setTimeout(() => {
      if (currentStepIndex < steps.length - 1) {
        console.log(`â¡ï¸ Advancing from step ${currentStepIndex} to ${currentStepIndex + 1}`);
        setCurrentStepIndex(prev => prev + 1);
      } else {
        console.log('âœ… Module completed, returning to module selection');
        // Stop any playing audio before completing module
        if (personaTransitionRef.current && personaTransitionRef.current.stopAudio) {
          personaTransitionRef.current.stopAudio();
        }
        onModuleComplete();
        setCurrentPage(Page.ModuleSelection); 
      }
      setIsChangingStep(false);
    }, 300);
  }, [currentStepIndex, steps.length, onModuleComplete, setCurrentPage, isChangingStep]);

  const handlePersonaNarrationEnd = useCallback(() => {
    console.log('Persona narration ended for step:', currentStep?.id, 'type:', currentStep?.type, 'content:', currentStep?.content);
    // For pure narration steps with no additional content, go directly to next step
    if (currentStep?.type === 'narration' && (!currentStep.content || (typeof currentStep.content === 'string' && currentStep.content.trim() === ''))) {
      console.log('Pure narration step - advancing directly to next step');
      handleNext();
    } else if (currentStep?.id === 'fn_detection_tips' || currentStep?.id === 'it_detection_tips') {
      // For detection tips, content was already shown during persona transition, so go to next step
      console.log('Detection tips completed - advancing to next step');
      handleNext();
    } else {
      // For steps with content, show the content view
      console.log('Step has content - showing content view');
      setCurrentView('content');
    }
  }, [currentStep, handleNext]);

  const handleQuizComplete = (score: number, total: number) => {
    console.log(`${moduleTitle} í€´ì¦ˆ ì™„ë£Œ: ${total}ì  ë§Œì ì— ${score}ì `);
    handleNext(); 
  };

  const handleReturnToModuleSelection = () => {
    console.log('Returning to module selection - stopping all audio first');
    // Stop any playing audio before navigating
    if (personaTransitionRef.current && personaTransitionRef.current.stopAudio) {
      personaTransitionRef.current.stopAudio();
    }
    setCurrentPage(Page.ModuleSelection);
  };
  
  if (!currentStep && currentView === 'content') { 
    return (
      <PageLayout title={moduleTitle}>
        <Card>
          <p className="text-center text-xl text-green-600">{moduleCompletionMessage}</p>
          <div className="mt-8 flex justify-center">
            {/* <Button onClick={handleReturnToModuleSelection} variant="primary" size="lg">
              ëª¨ë“ˆ ì„ íƒìœ¼ë¡œ ëŒì•„ê°€ê¸°
            </Button> */}
          </div>
        </Card>
      </PageLayout>
    );
  }

  // const getSectionTitle = (step: ModuleStep) => {
  //   if (!step) return "ì•ˆë‚´ ì¤‘...";
    
  //   // Module 1 (Fake News) sections
  //   if (moduleTitle === "ê°€ì§œ ë‰´ìŠ¤ë€?") {
  //     if (step.type === 'info' || step.type === 'narration') {
  //       return "1. ê°€ì§œ ë‰´ìŠ¤ ê°œë…";
  //     } else if (step.type === 'video_case_study') {
  //       return "2. ê°€ì§œ ë‰´ìŠ¤ ì‚¬ë¡€";
  //     } else if (step.type === 'faceswap_scenario') {
  //       return "3. ê°€ì§œ ë‰´ìŠ¤ ì²´í—˜";
  //     } else if (step.type === 'quiz' || step.type === 'video_identification_quiz') {
  //       return "4. ê°€ì§œ ë‰´ìŠ¤ ëŒ€ì‘";
  //     }
  //   }
    
  //   // Module 2 (Identity Theft) sections
  //   if (moduleTitle === "ì‹ ì› ë„ìš©ì´ë€?") {
  //     if (step.type === 'info' || step.type === 'narration') {
  //       return "1. ì‹ ì›ë„ìš© ê°œë…";
  //     } else if (step.type === 'video_case_study') {
  //       return "2. ì‹ ì›ë„ìš© ì‚¬ë¡€";
  //     } else if (step.type === 'voice_call_scenario' || step.type === 'video_call_scenario') {
  //       return "3. ì‹ ì›ë„ìš© ì²´í—˜";
  //     } else if (step.type === 'quiz' || step.type === 'video_identification_quiz') {
  //       return "4. ì‹ ì›ë„ìš© ëŒ€ì‘";
  //     }
  //   }
    
  //   return step.title;
  // };

  const getCurrentProgressSection = (step: ModuleStep) => {
    if (!step) return "ê°œë…";
    
    // Check step ID patterns to determine section
    const stepId = step.id;
    
    // Quiz sections are "í€´ì¦ˆ" (quiz)
    if (stepId.includes('quiz') && step.type === 'quiz') {
      return "í€´ì¦ˆ";
    }
    
    // Detection tips are part of "ëŒ€ì‘" (countermeasures)
    if (stepId.includes('detection')) {
      return "ëŒ€ì‘";
    }
    
    // Experience/scenario sections are "ì‹¤ìŠµ" (practice)
    if (stepId.includes('scenario') || stepId.includes('experience') || 
        step.type === 'faceswap_scenario' || step.type === 'voice_call_scenario' || step.type === 'video_call_scenario') {
      return "ì‹¤ìŠµ";
    }
    
    // Case study sections are "ì‚¬ë¡€" (examples)
    if (stepId.includes('case') || step.type === 'video_case_study') {
      return "ì‚¬ë¡€";
    }
    
    // Everything else (intro, concepts, definitions) are "ê°œë…" (concepts)
    return "ê°œë…";
  };

  const renderContentForStep = () => {
    if (!currentStep) return null;

    if (isLoadingStep) {
      return <div className="flex justify-center py-12"><LoadingSpinner text="ë¡œë”© ì¤‘..." /></div>;
    }

    if (stepError) {
      return <p className="text-red-600 text-center text-lg p-4 bg-red-50 rounded-md border border-red-300">{stepError}</p>;
    }

    // For detection tips, show the content while narrator speaks
    if (currentStep.id === 'fn_detection_tips' || currentStep.id === 'it_detection_tips') {
      return (
        <div className="mt-4">
          <div dangerouslySetInnerHTML={{ __html: currentStep.content || '' }} />
        </div>
      );
    }

    // For case studies, show a more detailed heading
    if (currentStep.type === 'video_case_study') {
      return (
        <div className="space-y-4">
          <h3 className="text-lg font-semibold text-orange-600">
            
          </h3>
          <div className="aspect-video bg-gray-100 rounded-lg border-2 border-orange-500 overflow-hidden">
            <video 
              controls 
              autoPlay
              className="w-full h-full object-cover"
              src={currentStep.videoUrl}
              playsInline
              preload="metadata"
              disablePictureInPicture
              onEnded={() => setVideoEnded(true)}
            >
              <p>ë¸Œë¼ìš°ì €ê°€ ë™ì˜ìƒì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
            </video>
          </div>
          <p className="text-sm text-slate-600 italic">
            ì´ ì˜ìƒì€ AI ê¸°ìˆ ë¡œ ë§Œë“¤ì–´ì§„ ê°€ì§œ ì˜ìƒì…ë‹ˆë‹¤.
          </p>
        </div>
      );
    }

    // Handle other step types
    switch (currentStep.type) {
      case 'quiz':
        const quizQuestions = currentStep.quizId ? QUIZZES[currentStep.quizId] : null;
        if (!quizQuestions) return <p className="text-red-500 text-lg">í€´ì¦ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>;
        return <QuizComponent 
          questions={quizQuestions} 
          onQuizComplete={handleQuizComplete} 
          voiceId={voiceId}
          onPrevious={currentStepIndex > 0 ? () => setCurrentStepIndex(prev => prev - 1) : undefined}
        />;
      
      case 'faceswap_scenario':
        console.log('ğŸ­ Rendering faceswap_scenario:', { 
          hasInteractiveContent: !!interactiveContent, 
          isLoadingStep,
          interactiveContentType: typeof interactiveContent 
        });
        return (
          <div className="text-center">
            {interactiveContent ? interactiveContent : (
              <div className="text-slate-700 text-lg">
                <LoadingSpinner size="lg" />
                <p className="mt-4">AI ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘...</p>
                <p className="text-sm text-slate-500 mt-2">ì´ ì‘ì—…ì€ ìµœëŒ€ 2ë¶„ê¹Œì§€ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
              </div>
            )}
          </div>
        );
      
      case 'voice_call_scenario':
        return (
          <div className="text-center">
            {interactiveContent ? interactiveContent : (
              <div className="bg-gray-900 text-white p-8 rounded-xl max-w-sm mx-auto">
                <div className="text-center">
                  <LoadingSpinner size="lg" />
                  <p className="text-lg font-semibold mt-4">ìŒì„± í†µí™” ì‹œë®¬ë ˆì´ì…˜</p>
                  <p className="text-sm mt-2">ìŒì„± ìƒì„± ì¤‘...</p>
                </div>
              </div>
            )}
          </div>
        );
      
      case 'video_call_scenario':
        return (
          <div className="text-center">
            {interactiveContent ? interactiveContent : (
              <div className="bg-gray-900 text-white p-8 rounded-xl max-w-md mx-auto">
                <div className="text-center">
                  <LoadingSpinner size="lg" />
                  <p className="text-lg font-semibold mt-4">ì˜ìƒ í†µí™” ì‹œë®¬ë ˆì´ì…˜</p>
                  <p className="text-sm mt-2">ë”¥í˜ì´í¬ ì˜ìƒ ìƒì„± ì¤‘...</p>
                </div>
              </div>
            )}
          </div>
        );
      
      default:
        // For other steps, show the content if available
        return currentStep.content ? (
          <div className="mt-4" dangerouslySetInnerHTML={{ __html: currentStep.content }} />
        ) : null;
    }
  };

  const showNextButtonForContent = currentView === 'content' && currentStep?.type !== 'quiz';

  return (
    <PageLayout
      title={moduleTitle}
      showAppTitle={false}
    >
      <div className="max-w-4xl mx-auto px-4 py-8">
        {/* Module Progress Bar */}
        <ModuleProgressBar 
          currentSection={getCurrentProgressSection(currentStep)}
          moduleType={moduleTitle === "ê°€ì§œ ë‰´ìŠ¤ë€?" ? 'fakeNews' : 'identityTheft'}
          className="mb-6"
        />
        
        <Card >
          
          {currentView === 'personaTransition' && currentStep ? (
            <>
              <PersonaTransitionSlide
                ref={personaTransitionRef}
                onNext={handlePersonaNarrationEnd}
                onPrevious={currentStepIndex > 0 ? () => setCurrentStepIndex(prev => prev - 1) : undefined}
                userData={userData}
                caricatureUrl={caricatureUrl}
                talkingPhotoUrl={talkingPhotoUrl}
                voiceId={voiceId}
                script={scriptForPersona}
                showScript={false}
                chunkedDisplay={true}
              />
              {/* For detection tips, show content during persona narration */}
              {(currentStep.id === 'fn_detection_tips' || currentStep.id === 'it_detection_tips') && (
                <div className="mt-8">
                  <div dangerouslySetInnerHTML={{ __html: currentStep.content || '' }} />
                </div>
              )}
            </>
          ) : currentView === 'content' && currentStep ? (
            <>
              <div className="min-h-[200px]">
                {renderContentForStep()}
              </div>
              {showNextButtonForContent && ( 
                <div className="mt-10 flex justify-center items-center space-x-4">
                  {/* {currentStepIndex > 0 && (
                    <BackButton
                      onClick={() => setCurrentStepIndex(prev => prev - 1)}
                      size="lg"
                      variant="primary"
                    />
                  )} */}
                  <ContinueButton 
                    onClick={handleNext} 
                    text={currentStepIndex === steps.length - 1 ? "ëª¨ë“ˆ ì™„ë£Œ" : "ê³„ì†"}
                    showAnimation={videoEnded}
                  />
                </div>
              )}
            </>
          ) : (
               <div className="min-h-[200px] flex items-center justify-center">
                  <LoadingSpinner text="ëª¨ë“ˆ ì¤€ë¹„ ì¤‘..." />
               </div>
          )}
        </Card>
         {/* <Button onClick={handleReturnToModuleSelection} variant="ghost" size="md" className="mt-8 mx-auto !text-slate-600 hover:!text-orange-600 hover:!bg-slate-200">
              ëª¨ë“ˆ ì„ íƒìœ¼ë¡œ ëŒì•„ê°€ê¸°
          </Button> */}
      </div>
    </PageLayout>
  );
};

export default BaseModulePage;
